{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import sklearn.model_selection as sklearn_model_selection\n",
    "import sklearn.linear_model as sklearn_linear\n",
    "import sklearn.feature_extraction.text as sklearn_text\n",
    "import sklearn.metrics as sklearn_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb_reviews = pd.read_csv(\"imdb_dataset_prepared.csv\")\n",
    "\n",
    "X = imdb_reviews[\"review\"]\n",
    "y = imdb_reviews[\"sentiment\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "vectorisation started\n",
      "vectorisation finished\n",
      "  (0, 151692)\t0.05746945406236768\n",
      "  (0, 695611)\t0.04099650902199992\n",
      "  (0, 637966)\t0.049319306965853855\n",
      "  (0, 303056)\t0.053272583456377906\n",
      "  (0, 242752)\t0.04094095228547884\n",
      "  (0, 108858)\t0.03752661699942309\n",
      "  (0, 705966)\t0.024901589802556162\n",
      "  (0, 294645)\t0.018648834207459476\n",
      "  (0, 319913)\t0.06691359288348196\n",
      "  (0, 679242)\t0.029924801945832673\n",
      "  (0, 695508)\t0.04135906705930563\n",
      "  (0, 131335)\t0.05689758557971741\n",
      "  (0, 375359)\t0.06209357594610185\n",
      "  (0, 706456)\t0.03730443150034943\n",
      "  (0, 453177)\t0.07255265120589836\n",
      "  (0, 671922)\t0.07255265120589836\n",
      "  (0, 201598)\t0.06773263426851825\n",
      "  (0, 444267)\t0.07455313898207028\n",
      "  (0, 543120)\t0.06249104495492012\n",
      "  (0, 429943)\t0.05727355900872175\n",
      "  (0, 341905)\t0.03092397425308388\n",
      "  (0, 609624)\t0.05689758557971741\n",
      "  (0, 633282)\t0.03521432097235336\n",
      "  (0, 311611)\t0.06491310510731005\n",
      "  (0, 644479)\t0.04341856917438987\n",
      "  :\t:\n",
      "  (49999, 672487)\t0.02966945214110952\n",
      "  (49999, 700605)\t0.08627131236159445\n",
      "  (49999, 103257)\t0.021983345160694556\n",
      "  (49999, 523351)\t0.052430920005815444\n",
      "  (49999, 439820)\t0.026340926593672775\n",
      "  (49999, 701458)\t0.0736220645201551\n",
      "  (49999, 22191)\t0.03597890689959661\n",
      "  (49999, 590334)\t0.040377804372623595\n",
      "  (49999, 227357)\t0.03004625177295268\n",
      "  (49999, 317673)\t0.037635970738658604\n",
      "  (49999, 619447)\t0.028157393603496252\n",
      "  (49999, 675144)\t0.028351382779231597\n",
      "  (49999, 516472)\t0.032470987406373594\n",
      "  (49999, 700947)\t0.026726660710080574\n",
      "  (49999, 207663)\t0.08257438751051802\n",
      "  (49999, 276815)\t0.04628885343885774\n",
      "  (49999, 546930)\t0.02217921377105779\n",
      "  (49999, 410715)\t0.026757256329344118\n",
      "  (49999, 517877)\t0.029184792871916044\n",
      "  (49999, 6328)\t0.023426900011528626\n",
      "  (49999, 376430)\t0.02781667694347531\n",
      "  (49999, 707102)\t0.05086499618551711\n",
      "  (49999, 191590)\t0.049470960481171035\n",
      "  (49999, 333012)\t0.023335260839238255\n",
      "  (49999, 671633)\t0.036001987423205116\n",
      "(50000, 710400)\n"
     ]
    }
   ],
   "source": [
    "print(\"vectorisation started\")\n",
    "tfidf = sklearn_text.TfidfVectorizer(min_df=2, max_df=0.5, ngram_range=(1,2))\n",
    "\n",
    "X = tfidf.fit_transform(X)\n",
    "print(\"vectorisation finished\")\n",
    "print(X)\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "logistic regression training started\n",
      "logistic regression training finished\n",
      "Accuancy: 89.97 %\n",
      "[[4420  591]\n",
      " [ 412 4577]]\n"
     ]
    }
   ],
   "source": [
    "print(\"logistic regression training started\")\n",
    "\n",
    "X_train, X_test, y_train, y_test = sklearn_model_selection.train_test_split(X, y, test_size=0.2, shuffle=True)\n",
    "\n",
    "logistic_model = sklearn_linear.LogisticRegression(max_iter=1000)\n",
    "logistic_model.fit(X_train, y_train)\n",
    "\n",
    "print(\"logistic regression training finished\")\n",
    "\n",
    "y_predicted = logistic_model.predict(X_test)\n",
    "\n",
    "print(\"Accuancy: {:.2f} %\".format(sklearn_metrics.accuracy_score(y_test, y_predicted) * 100))\n",
    "print(sklearn_metrics.confusion_matrix(y_test, y_predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Negative:\n"
     ]
    }
   ],
   "source": [
    "top_phrase_count = 20\n",
    "tfidf_feature_names = tfidf.get_feature_names()\n",
    "\n",
    "print(\"Negative:\")\n",
    "top_negative_phrases_indexes = np.argsort(logistic_model.coef_[0])[:top_phrase_count]\n",
    "top_negative_phrases = [tfidf_feature_names[z] for z in top_negative_phrases_indexes]\n",
    "print(top_negative_phrases)\n",
    "\n",
    "print(\"Positive:\")\n",
    "top_positive_phrases_indexes = np.argsort(logistic_model.coef_[0])[-top_phrase_count:]\n",
    "top_positive_phrases = [tfidf_feature_names[z] for z in top_positive_phrases_indexes]\n",
    "print(top_positive_phrases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}